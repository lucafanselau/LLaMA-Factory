model_name_or_path: Qwen/Qwen3-VL-2B-Instruct
template: qwen3_vl_nothink
trust_remote_code: true
stage: sft
do_train: true
finetuning_type: lora
freeze_vision_tower: true
freeze_multi_modal_projector: true
freeze_language_model: false
image_max_pixels: 262144
image_min_pixels: 512
video_max_pixels: 16384
video_min_pixels: 256
dataset: OVIS_train_qwen3_single_image,OVIS_train_qwen3_multi_image_single_turn,OVIS_train_qwen3_multi_image_multi_turn
eval_dataset: OVIS_val_qwen3_single_image,OVIS_val_qwen3_multi_image_single_turn,OVIS_val_qwen3_multi_image_multi_turn
eval_on_each_dataset: false
dataset_dir: /storage/user/falu/vis/processed
media_dir: /storage/user/falu/vis
cutoff_len: 8192
max_samples: null
overwrite_cache: false
use_fast_tokenizer: true
preprocessing_num_workers: 48
dataloader_num_workers: 4
tokenized_path: /storage/user/falu/vis/processed/tokenized/qwen3/OVIS_single_image_multi_image_single_turn_multi_image_multi_turn
output_dir: /storage/user/falu/trained_models/qwen3_vl_2b/lora/OVIS_single_image_multi_image_single_turn_multi_image_multi_turn
per_device_train_batch_size: 2
per_device_eval_batch_size: 2
gradient_accumulation_steps: 8
learning_rate: 5.0e-05
num_train_epochs: 6
lr_scheduler_type: cosine
warmup_ratio: 0.1
bf16: true
ddp_timeout: 180000000
max_grad_norm: 1.0
eval_strategy: steps
eval_steps: 0.5
save_strategy: steps
save_steps: 100
logging_steps: 10
log_level: info
save_only_model: false
overwrite_output_dir: true
plot_loss: true
report_to: wandb
run_name: qwen3_vl_2b_OVIS_single_image_multi_image_single_turn_multi_image_multi_turn
optim: adamw_torch
resume_from_checkpoint: null
lora_rank: 8
lora_alpha: 16
lora_dropout: 0.1
lora_target: q_proj,v_proj
create_new_adapter: true
